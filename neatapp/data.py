from typing import Dict, Sequence

from llama_index.core.output_parsers import PydanticOutputParser
from llama_index.core.program import MultiModalLLMCompletionProgram
from llama_index.core.schema import ImageDocument

from neatapp.models import Restaurant
from neatapp.utils import get_multi_modal_llm


def extract_data(
    image_documents: Sequence[ImageDocument],
    data_extract_str: str,
    llm_name: str,
    model_temperature: int,
    api_key: str,
) -> Dict:
    """Extract data from image document

    Args:
        image_documents (Sequence[ImageDocument]): List of the ImageDocument
        data_extract_str (str): A prompt message used to instruct the LLM to generate desired response
        llm_name (str): name of the OpenAI LLM
        model_temperature (int): model temperature ranging from 0-1
        api_key (str): OPENAI_API_KEY used to authenticate with the OpenAI platform

    Returns:
        Dict: response generated by the LLM
    """
    llm = get_multi_modal_llm(llm_name, model_temperature, api_key, max_new_tokens=1000)
    openai_program = MultiModalLLMCompletionProgram.from_defaults(
        output_parser=PydanticOutputParser(Restaurant),
        image_documents=image_documents,
        prompt_template_str=data_extract_str,
        multi_modal_llm=llm,
        verbose=True,
    )
    response = openai_program()
    return response
